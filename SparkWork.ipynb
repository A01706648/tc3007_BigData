{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e84fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hu/spark-3.2.2-bin-hadoop3.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/hu/spark-3.2.2-bin-hadoop3.2\"\n",
    "\n",
    "#Buscando e inicializando la instalaci√≥n de Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926045fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/18 15:47:45 WARN Utils: Your hostname, hu-ThinkPad-W520 resolves to a loopback address: 127.0.1.1; using 192.168.1.96 instead (on interface wlp3s0)\n",
      "22/11/18 15:47:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hu/spark-3.2.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/18 15:47:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df_ml = SparkSession.builder.appName('iris').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d926705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| Setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| Setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| Setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| Setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| Setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| Setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| Setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| Setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| Setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| Setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| Setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| Setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = df_ml.read.csv('iris.csv', header = True, inferSchema=True)\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fff229",
   "metadata": {},
   "source": [
    "To work with regression models we have to use *VectorAssembler* to convert the independent variables into a vector that includes them  \n",
    "\n",
    "vectorize all numerical columns into a single feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f00d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4fd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = dataset.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac2723",
   "metadata": {},
   "source": [
    "Later they are integrated into the dataset that was already loaded using the *transform()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9a3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|         features|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|[5.0,3.6,1.4,0.2]|\n",
      "|         5.4|        3.9|         1.7|        0.4| Setosa|[5.4,3.9,1.7,0.4]|\n",
      "|         4.6|        3.4|         1.4|        0.3| Setosa|[4.6,3.4,1.4,0.3]|\n",
      "|         5.0|        3.4|         1.5|        0.2| Setosa|[5.0,3.4,1.5,0.2]|\n",
      "|         4.4|        2.9|         1.4|        0.2| Setosa|[4.4,2.9,1.4,0.2]|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|[4.9,3.1,1.5,0.1]|\n",
      "|         5.4|        3.7|         1.5|        0.2| Setosa|[5.4,3.7,1.5,0.2]|\n",
      "|         4.8|        3.4|         1.6|        0.2| Setosa|[4.8,3.4,1.6,0.2]|\n",
      "|         4.8|        3.0|         1.4|        0.1| Setosa|[4.8,3.0,1.4,0.1]|\n",
      "|         4.3|        3.0|         1.1|        0.1| Setosa|[4.3,3.0,1.1,0.1]|\n",
      "|         5.8|        4.0|         1.2|        0.2| Setosa|[5.8,4.0,1.2,0.2]|\n",
      "|         5.7|        4.4|         1.5|        0.4| Setosa|[5.7,4.4,1.5,0.4]|\n",
      "|         5.4|        3.9|         1.3|        0.4| Setosa|[5.4,3.9,1.3,0.4]|\n",
      "|         5.1|        3.5|         1.4|        0.3| Setosa|[5.1,3.5,1.4,0.3]|\n",
      "|         5.7|        3.8|         1.7|        0.3| Setosa|[5.7,3.8,1.7,0.3]|\n",
      "|         5.1|        3.8|         1.5|        0.3| Setosa|[5.1,3.8,1.5,0.3]|\n",
      "+------------+-----------+------------+-----------+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_feature = assembler.transform(dataset)\n",
    "dataset_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a24344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "|[5.4,3.9,1.7,0.4]|  0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|\n",
      "|[5.0,3.4,1.5,0.2]|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|\n",
      "|[5.4,3.7,1.5,0.2]|  0.0|\n",
      "|[4.8,3.4,1.6,0.2]|  0.0|\n",
      "|[4.8,3.0,1.4,0.1]|  0.0|\n",
      "|[4.3,3.0,1.1,0.1]|  0.0|\n",
      "|[5.8,4.0,1.2,0.2]|  0.0|\n",
      "|[5.7,4.4,1.5,0.4]|  0.0|\n",
      "|[5.4,3.9,1.3,0.4]|  0.0|\n",
      "|[5.1,3.5,1.4,0.3]|  0.0|\n",
      "|[5.7,3.8,1.7,0.3]|  0.0|\n",
      "|[5.1,3.8,1.5,0.3]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text labels into indexed label\n",
    "dataset_feature_label = dataset_feature.select(['features', 'variety'])\n",
    "label_indexer = StringIndexer(inputCol='variety', outputCol='label').fit(dataset_feature_label)\n",
    "dataset_feature_label_indexed = label_indexer.transform(dataset_feature_label)\n",
    "\n",
    "# only select the features and indexed label column\n",
    "dataset_feature_label_indexed = dataset_feature_label_indexed.select(['features', 'label'])\n",
    "dataset_feature_label_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c0c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set regularization rate\n",
    "reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38166162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Logistic Regression to train on the training set\n",
    "train, test = dataset_feature_label_indexed.randomSplit([0.75, 0.25])\n",
    "lr = LogisticRegression(regParam=reg)\n",
    "#model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d82b247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k folder cross validation\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#modelEvaluator=RegressionEvaluator()\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).addGrid(lr.elasticNetParam, [0, 1]).build()\n",
    "\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "cvModel = crossval.fit(test)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d97e61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the summery of cross validation\n",
    "trainingSummary = cvModel.bestModel.summary\n",
    "trainingSummary.objectiveHistory\n",
    "trainingSummary.totalIterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c5a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|         features|label|       rawPrediction|         probability|prediction|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "|[4.4,3.0,1.3,0.2]|  0.0|[4.71991255911337...|[0.98278420914390...|       0.0|\n",
      "|[4.5,2.3,1.3,0.3]|  0.0|[4.71991255911337...|[0.95289140284613...|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|  0.0|[4.45095390056219...|[0.98324293341434...|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|  0.0|[4.45095390056219...|[0.98748778586317...|       0.0|\n",
      "|[4.6,3.6,1.0,0.2]|  0.0|[5.52678853476693...|[0.99679787624147...|       0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|[4.71991255911337...|[0.98714386713815...|       0.0|\n",
      "|[4.7,3.2,1.6,0.2]|  0.0|[3.91303658345982...|[0.97164311881975...|       0.0|\n",
      "|[4.8,3.0,1.4,0.1]|  0.0|[4.45095390056219...|[0.97759050539651...|       0.0|\n",
      "|[4.8,3.0,1.4,0.3]|  0.0|[4.45095390056219...|[0.97759034514026...|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|  0.0|[4.18199524201100...|[0.97478711772592...|       0.0|\n",
      "+-----------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "#prediction = model.transform(test)\n",
    "prediction = cvModel.transform(test)\n",
    "prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd2d5c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy is 100.0%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model using the test set\n",
    "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "print('Prediction Accuracy is ' + str(accuracy * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
